from __future__ import annotations

import logging
import os
import re
import sys
import uuid
from pathlib import Path
from typing import Any, List, Tuple, cast

import streamlit as st
from dotenv import load_dotenv

# Ensure project root is on sys.path so that 'app' package is importable
PROJECT_ROOT = Path(__file__).resolve().parent.parent
if str(PROJECT_ROOT) not in sys.path:
    sys.path.insert(0, str(PROJECT_ROOT))

from app.auth import render_login_gate, render_sidebar_user
from app.export import export_docx, export_pdf
from app.file_handler import process_uploaded_file_with_gemini
from app.llm import (
    DEFAULT_MODEL_NAME,
    bootstrap_spec,
    check_spec_completeness,
    generate_title,
    next_questions,
    regenerate_spec,
)
from app.spec_builder import append_assistant_message, append_user_answer
from app.state import AppState, Attachment, Idea
from app.storage import delete_idea, get_idea, load_ideas, save_ideas

APP_TITLE = "Patent Chat"
DEFAULT_CATEGORY = "é˜²ç½"
PROJECT_ROOT = Path(__file__).resolve().parent.parent

# Suppress very noisy PDF parsing warnings (e.g., advanced encodings)
logging.getLogger("pypdf").setLevel(logging.ERROR)


def _load_instruction_markdown() -> str:
    """Load drafting instruction document with fallback to sample.md."""
    primary = PROJECT_ROOT / "LLM_Prompt_for_Patent_Application_Drafting_from_Idea.md"
    fallback = PROJECT_ROOT / "sample.md"
    path = primary if primary.exists() else fallback
    try:
        return path.read_text(encoding="utf-8")
    except Exception:
        return ""


def _clean_ai_message(content: str) -> str:
    """AIãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‹ã‚‰å°å…¥éƒ¨åˆ†ã‚’é™¤å¤–ã—ã¦æœ¬æ–‡ã®ã¿è¿”ã™."""
    if not content:
        return ""

    # é™¤å¤–ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆä¸€èˆ¬çš„ãªå°å…¥è¡¨ç¾ï¼‰
    intro_patterns = [
        r'^æ‰¿çŸ¥.*?ã€‚\s*',
        r'^äº†è§£.*?ã€‚\s*',
        r'^ç¢ºèªã•ã›ã¦.*?ã€‚\s*',
        r'^ã‚ã‹ã‚Šã¾ã—ãŸ.*?ã€‚\s*',
        r'^ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™.*?ã€‚\s*',
        r'^ãã‚Œã§ã¯.*?ã€‚\s*',
        r'^ä»¥ä¸‹.*?ç¢ºèª.*?ã€‚\s*',
        r'^æ¬¡ã®ç‚¹ã«ã¤ã„ã¦.*?ã€‚\s*',
        r'^è¿½åŠ ã§ç¢ºèª.*?ã€‚\s*',
    ]

    cleaned = content.strip()

    # å„ãƒ‘ã‚¿ãƒ¼ãƒ³ã§å°å…¥éƒ¨åˆ†ã‚’é™¤å»
    for pattern in intro_patterns:
        cleaned = re.sub(pattern, '', cleaned, flags=re.MULTILINE | re.DOTALL)

    # å†’é ­ã®ç©ºè¡Œã‚’é™¤å»
    cleaned = re.sub(r'^\s*\n+', '', cleaned)

    return cleaned.strip()


def init_session_state() -> None:
    if "app_state" not in st.session_state:
        default_model = os.getenv("GEMINI_MODEL", DEFAULT_MODEL_NAME)
        st.session_state.app_state = AppState(gemini_model=default_model)
        os.environ["GEMINI_MODEL"] = default_model
    if "ideas" not in st.session_state:
        st.session_state.ideas = load_ideas()


def sidebar_ui():
    ideas: List[Idea] = st.session_state.ideas
    state: AppState = st.session_state.app_state

    # Always-available Home navigation (without logging out)
    if st.sidebar.button("ğŸ  ãƒˆãƒƒãƒ—ã¸æˆ»ã‚‹", use_container_width=True):
        state.selected_idea_id = None
        state.show_new_idea_form = False
        # Clear transient flags such as hearing start
        if "start_hearing" in st.session_state:
            st.session_state.pop("start_hearing", None)
        st.rerun()

    model_options = ["gemini-2.5-pro", "gemini-2.5-flash"]
    current_index = (
        model_options.index(state.gemini_model) if state.gemini_model in model_options else 0
    )
    selected_model = st.sidebar.selectbox("Geminiãƒ¢ãƒ‡ãƒ«", model_options, index=current_index)
    if selected_model != state.gemini_model:
        state.gemini_model = selected_model
        os.environ["GEMINI_MODEL"] = selected_model

    # Move the idea list title below the model selector
    st.sidebar.title("ã‚¢ã‚¤ãƒ‡ã‚¢ä¸€è¦§")

    # New idea button
    if st.sidebar.button("ï¼‹ æ–°è¦ã‚¢ã‚¤ãƒ‡ã‚¢ã‚’ä½œæˆ", use_container_width=True):
        state.show_new_idea_form = True
        st.rerun()

    # Idea list
    for idea in ideas:
        cols = st.sidebar.columns([0.7, 0.15, 0.15])
        if cols[0].button(f"{idea.title or '(ç„¡é¡Œ)'}", key=f"sel-{idea.id}"):
            state.selected_idea_id = idea.id
            state.show_new_idea_form = False
            st.rerun()
        if cols[1].button("ç·¨é›†", key=f"edit-{idea.id}"):
            state.selected_idea_id = idea.id
            state.show_new_idea_form = True
            st.rerun()
        if cols[2].button("å‰Šé™¤", key=f"del-{idea.id}"):
            st.session_state.ideas = delete_idea(ideas, idea.id)
            save_ideas(st.session_state.ideas)
            if state.selected_idea_id == idea.id:
                state.selected_idea_id = None
            st.rerun()


def new_idea_form():
    st.subheader("æ–°è¦ã‚¢ã‚¤ãƒ‡ã‚¢")
    category = st.selectbox(
        "ã‚«ãƒ†ã‚´ãƒª", ["é˜²ç½", "åŒ»ç™‚", "è£½é€ ", "ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢", "ç’°å¢ƒ", "ãã®ä»–"], index=0
    )
    description = st.text_area(
        "ã‚¢ã‚¤ãƒ‡ã‚¢ã®è©³ç´°èª¬æ˜", height=160, placeholder="ã‚¢ã‚¤ãƒ‡ã‚¢ã®æ¦‚è¦ã‚’è¨˜è¼‰â€¦"
    )

    # File upload section
    st.markdown("### é–¢é€£ãƒ•ã‚¡ã‚¤ãƒ«ã®æ·»ä»˜ï¼ˆä»»æ„ï¼‰")
    uploaded_files = st.file_uploader(
        "ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠ",
        accept_multiple_files=True,
        help="ãƒ†ã‚­ã‚¹ãƒˆã€PDFã€ç”»åƒã€Wordã€PowerPointãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã§ãã¾ã™ï¼ˆå„10MBä»¥å†…ï¼‰",
    )

    # Process uploaded files
    attachments_to_add = []
    if uploaded_files:
        for uploaded_file in uploaded_files:
            comment = st.text_input(
                f"{uploaded_file.name} ã¸ã®ã‚³ãƒ¡ãƒ³ãƒˆ",
                placeholder="ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã®èª¬æ˜ã‚’å…¥åŠ›...",
                key=f"comment_{uploaded_file.name}",
            )
            attachments_to_add.append((uploaded_file, comment))

    cols = st.columns(2)
    if cols[0].button("ä¿å­˜", type="primary"):
        idea_id = str(uuid.uuid4())
        with st.status("å‡¦ç†ã‚’é–‹å§‹ã—ã¾ã™â€¦", expanded=True) as status:
            status.update(label="ã‚¿ã‚¤ãƒˆãƒ«ç”Ÿæˆä¸­â€¦", state="running")
            title = generate_title(description)

            # Process attachments
            status.update(label="æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†ä¸­â€¦", state="running")
            attachments = []
            attachment_dicts = []
            gemini_files: List[Any] = []

            # Get Gemini client to fetch file objects
            import logging
            import os

            from google import genai

            logger = logging.getLogger("patent_chat.main")
            api_key = os.getenv("GOOGLE_API_KEY") or os.getenv("GEMINI_API_KEY")
            gemini_client = None
            if api_key:
                try:
                    gemini_client = genai.Client(api_key=api_key)
                except Exception:
                    pass

            for uploaded_file, comment in attachments_to_add:
                try:
                    file_data = process_uploaded_file_with_gemini(uploaded_file, comment)
                    attachment = Attachment(
                        filename=file_data["filename"],
                        content_base64=file_data["content_base64"],
                        comment=file_data["comment"],
                        file_type=file_data["file_type"],
                        upload_time=file_data["upload_time"],
                        gemini_file_id=file_data.get("gemini_file_id"),
                        gemini_mime_type=file_data.get("gemini_mime_type"),
                        extracted_text=file_data.get("extracted_text"),
                    )
                    attachments.append(attachment)
                    attachment_dicts.append(
                        {
                            "filename": file_data["filename"],
                            "extracted_text": file_data["extracted_text"],
                            "comment": file_data["comment"],
                        }
                    )

                    # Add Gemini file object if available
                    if file_data.get("gemini_file_id") and gemini_client:
                        try:
                            # Get the actual file object from Gemini
                            gemini_file = gemini_client.files.get(name=file_data["gemini_file_id"])
                            gemini_files.append(gemini_file)
                        except Exception:
                            file_id = file_data['gemini_file_id']
                            logger.warning(f"Failed to get Gemini file object for {file_id}")
                    elif file_data.get("gemini_file_id"):
                        # No client available, just store the ID
                        gemini_files.append(file_data["gemini_file_id"])

                except Exception as e:
                    st.warning(f"ãƒ•ã‚¡ã‚¤ãƒ« {uploaded_file.name} ã®å‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")

            status.update(label="ã‚¢ã‚¤ãƒ‡ã‚¢ã‚’ä¿å­˜ä¸­â€¦", state="running")
            idea = Idea(
                id=idea_id,
                title=title,
                category=category,
                description=description,
                attachments=attachments,
            )
            st.session_state.ideas.append(idea)
            save_ideas(st.session_state.ideas)

            status.update(label="åˆæœŸãƒ‰ãƒ©ãƒ•ãƒˆç”Ÿæˆä¸­â€¦", state="running")
            manual_md = _load_instruction_markdown()
            spec_result, error_msg = bootstrap_spec(
                manual_md, idea.description, attachments=attachment_dicts, gemini_files=gemini_files
            )
            if error_msg:
                st.error(f"âš ï¸ {error_msg}")
                st.info("åŸºæœ¬çš„ãªéª¨æ ¼ã‚’ç”Ÿæˆã—ã¾ã—ãŸã€‚å¾Œã§å†ç”Ÿæˆã‚’è©¦ã—ã¦ãã ã•ã„ã€‚")
            idea.draft_spec_markdown = spec_result
            save_ideas(st.session_state.ideas)

            status.update(label="åˆå›è³ªå•ã‚’æº–å‚™ä¸­â€¦", state="running")
            qs, q_error = next_questions(
                manual_md,
                idea.messages,
                idea.draft_spec_markdown,
                num_questions=5,
                version=idea.draft_version,
                is_final=idea.is_final,
                attachments=attachment_dicts,
            )
            if q_error:
                st.warning(f"âš ï¸ è³ªå•ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {q_error}")
                st.info("ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®è³ªå•ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
            for q in qs:
                append_assistant_message(idea.messages, q)
            save_ideas(st.session_state.ideas)

            status.update(label="å®Œäº†", state="complete")

        st.session_state.app_state.selected_idea_id = idea_id
        st.session_state.app_state.show_new_idea_form = False
        st.session_state.start_hearing = True
        st.rerun()
    if cols[1].button("ã‚­ãƒ£ãƒ³ã‚»ãƒ«"):
        st.session_state.app_state.show_new_idea_form = False


def edit_idea_form(idea: Idea):
    st.subheader("ã‚¢ã‚¤ãƒ‡ã‚¢ç·¨é›†")
    title = st.text_input("ã‚¿ã‚¤ãƒˆãƒ«", value=idea.title)
    categories = ["é˜²ç½", "åŒ»ç™‚", "è£½é€ ", "ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢", "ç’°å¢ƒ", "ãã®ä»–"]
    try:
        idx = categories.index(idea.category)
    except ValueError:
        idx = 0
    category = st.selectbox("ã‚«ãƒ†ã‚´ãƒª", categories, index=idx)
    description = st.text_area("ã‚¢ã‚¤ãƒ‡ã‚¢ã®è©³ç´°èª¬æ˜", value=idea.description, height=160)
    if st.button("æ›´æ–°"):
        idea.title = title
        idea.category = category
        idea.description = description
        save_ideas(st.session_state.ideas)
        st.success("æ›´æ–°ã—ã¾ã—ãŸã€‚")


def _calculate_question_start_number(idea: Idea) -> int:
    """Calculate the starting number for questions based on all previous questions."""
    # Count all assistant messages that are questions (answered or not)
    question_count = 0
    for msg in idea.messages:
        if msg.get("role") == "assistant":
            # Simple heuristic: if it contains "ï¼Ÿ" or "?", it's likely a question
            content = msg.get("content", "")
            if "ï¼Ÿ" in content or "?" in content:
                question_count += 1

    # If we're on the first version or no questions yet, start from 1
    if question_count == 0:
        return 1

    # Count only answered questions (pairs of assistant followed by user)
    answered_count = 0
    i = 0
    while i < len(idea.messages):
        # Look for assistant messages
        if i < len(idea.messages) and idea.messages[i].get("role") == "assistant":
            # Check if there's at least one user answer after this batch of questions
            j = i
            # Skip all consecutive assistant messages
            while j < len(idea.messages) and idea.messages[j].get("role") == "assistant":
                j += 1
            # Now j points to first non-assistant message or end
            # Check if there are user messages
            if j < len(idea.messages) and idea.messages[j].get("role") == "user":
                # Count the assistant messages in this batch as answered
                for k in range(i, j):
                    content = idea.messages[k].get("content", "")
                    if "ï¼Ÿ" in content or "?" in content:
                        answered_count += 1
            i = j
        else:
            i += 1

    # Start numbering from answered_count + 1
    return answered_count + 1


def _prepare_attachment_dicts(idea: Idea) -> Tuple[List[dict], List]:
    """Convert Attachment objects to dictionaries for LLM functions.

    Returns:
        Tuple of (attachment_dicts, gemini_files)
    """
    import base64

    from app.file_handler import extract_text_from_file

    attachment_dicts = []
    gemini_files: List[Any] = []

    # Get Gemini client to fetch file objects
    import logging
    import os

    from google import genai

    logger = logging.getLogger("patent_chat.main")
    api_key = os.getenv("GOOGLE_API_KEY") or os.getenv("GEMINI_API_KEY")
    gemini_client = None
    if api_key:
        try:
            gemini_client = genai.Client(api_key=api_key)
        except Exception:
            pass

    for att in idea.attachments:
        # Check if we have a Gemini file ID
        if att.gemini_file_id and gemini_client:
            try:
                # Get the actual file object from Gemini
                gemini_file = gemini_client.files.get(name=att.gemini_file_id)
                gemini_files.append(gemini_file)
            except Exception:
                logger.warning(f"Failed to get Gemini file object for {att.gemini_file_id}")
        elif att.gemini_file_id:
            # No client available, just store the ID
            gemini_files.append(cast(Any, att.gemini_file_id))
            # Still add to dicts for backward compatibility
            attachment_dicts.append(
                {
                    "filename": att.filename,
                    "extracted_text": "",  # Will be processed by Gemini directly
                    "comment": att.comment,
                }
            )
        else:
            # No Gemini file ID: use stored extracted_text if available to avoid re-parsing
            if getattr(att, "extracted_text", None):
                attachment_dicts.append(
                    {
                        "filename": att.filename,
                        "extracted_text": att.extracted_text or "",
                        "comment": att.comment,
                    }
                )
            else:
                # Fall back to local extraction
                file_bytes = base64.b64decode(att.content_base64)
                extracted_text = extract_text_from_file(file_bytes, att.filename)
                attachment_dicts.append(
                    {
                        "filename": att.filename,
                        "extracted_text": extracted_text,
                        "comment": att.comment,
                    }
                )

    return attachment_dicts, gemini_files


def _render_hearing_section(idea: Idea, manual_md: str, show_questions_first: bool = False):
    """å…±é€šã®è³ªå•è¡¨ç¤ºãƒ­ã‚¸ãƒƒã‚¯."""
    # Hearing round equals draft version
    hearing_round = idea.draft_version

    st.subheader(f"AI ãƒ’ã‚¢ãƒªãƒ³ã‚°ï¼ˆç¬¬{hearing_round}å›ï¼‰")

    # Collect consecutive assistant messages at the tail (unanswered)
    tail_assistant: list[str] = []
    for m in reversed(idea.messages):
        if m.get("role") == "assistant":
            tail_assistant.append(m.get("content", ""))
        else:
            break
    tail_assistant = list(reversed(tail_assistant))

    # Heuristic: keep only yes/no style questions for the radio form
    def _looks_like_yes_no_question(text: str) -> bool:
        if not text:
            return False
        t = str(text).strip()
        if "ã¯ã„/ã„ã„ãˆ" in t or "ï¼ˆã¯ã„/ã„ã„ãˆ" in t:
            return True
        if t.endswith("ï¼Ÿ") or t.endswith("?"):
            return True
        return False

    pending_candidates = [q for q in tail_assistant if _looks_like_yes_no_question(q)]
    # De-duplicate while preserving order
    seen_q: set[str] = set()
    pending_questions: list[str] = []
    for q in pending_candidates:
        if q not in seen_q:
            seen_q.add(q)
            pending_questions.append(q)
    pending_questions = pending_questions[:5]

    # Determine which trailing assistant messages to hide from the history
    # (exactly those shown in the pending questions)
    to_hide_indices = set()
    match_from_end = list(reversed(pending_questions))
    ptr = 0
    for idx in range(len(idea.messages) - 1, -1, -1):
        if ptr >= len(match_from_end):
            break
        m = idea.messages[idx]
        if m.get("role") != "assistant":
            break
        if m.get("content", "") == match_from_end[ptr]:
            to_hide_indices.add(idx)
            ptr += 1

    # For version 2+, show questions first if requested
    if show_questions_first and pending_questions:
        _render_pending_questions(idea, pending_questions, manual_md)

    # Conversation history (exclude pending questions to avoid duplication)
    if any(i not in to_hide_indices for i in range(len(idea.messages))):
        # Properly pair questions and answers considering batch format
        # Filter out pending questions first
        filtered_messages = []
        for i, msg in enumerate(idea.messages):
            if i not in to_hide_indices:
                filtered_messages.append(msg)

        # Collect questions and answers in batches
        questions = []
        answers = []

        j = 0
        while j < len(filtered_messages):
            # Collect consecutive assistant messages
            batch_questions = []
            while j < len(filtered_messages) and filtered_messages[j]["role"] == "assistant":
                batch_questions.append(_clean_ai_message(filtered_messages[j]['content']))
                j += 1

            # Collect consecutive user messages
            batch_answers = []
            while j < len(filtered_messages) and filtered_messages[j]["role"] == "user":
                batch_answers.append(filtered_messages[j]['content'])
                j += 1

            # Pair this batch
            for k in range(len(batch_questions)):
                if k < len(batch_answers):
                    questions.append(batch_questions[k])
                    answers.append(batch_answers[k])

        # Display Q&A history in expander for version 2+
        if show_questions_first and questions:
            with st.expander("**ã“ã‚Œã¾ã§ã®è³ªå•ã¨å›ç­”**", expanded=False):
                # Display paired Q&A
                for q, a in zip(questions, answers):
                    st.markdown(f"{q}: {a}")
        elif not show_questions_first and questions:
            # Version 1: display inline
            for q, a in zip(questions, answers):
                st.markdown(f"{q}: {a}")

    # Pending assistant questions at tail -> per-question radios (ã¯ã„/ã„ã„ãˆ/ã‚ã‹ã‚‰ãªã„)
    if not show_questions_first and pending_questions:
        _render_pending_questions(idea, pending_questions, manual_md)


def _render_pending_questions(idea: Idea, pending_questions: list[str], manual_md: str):
    """Render pending questions form."""
    st.markdown("**æœªå›ç­”ã®è³ªå•**ï¼ˆå„é …ç›®ã«å›ç­”ã—ã¦ã€Œå›ç­”ã‚’ã¾ã¨ã‚ã¦é€ä¿¡ã€ï¼‰")
    with st.form(f"qa-form-{idea.id}"):
        selections: list[str] = []
        # Calculate the starting question number based on all previous questions
        start_num = _calculate_question_start_number(idea)
        for i, q in enumerate(pending_questions, start=start_num):
            cleaned_q = _clean_ai_message(q)
            st.markdown(f"Q{i}: {cleaned_q}")
            # Use draft version in key to ensure fresh state for each round
            choice = st.radio(
                key=f"ans-{idea.id}-v{idea.draft_version}-{i}",
                label="å›ç­”",
                options=["ã¯ã„", "ã„ã„ãˆ", "ã‚ã‹ã‚‰ãªã„"],
                index=2,  # Default to "ã‚ã‹ã‚‰ãªã„"
                horizontal=True,
            )
            selections.append(choice)
        submitted = st.form_submit_button("å›ç­”ã‚’ã¾ã¨ã‚ã¦é€ä¿¡", type="primary")
        if submitted:
            for ans in selections:
                append_user_answer(idea.messages, ans)
            with st.spinner("ãƒ‰ãƒ©ãƒ•ãƒˆæ›´æ–°ä¸­â€¦"):
                attachment_dicts, gemini_files = _prepare_attachment_dicts(idea)
                spec_result, error_msg = regenerate_spec(
                    manual_md,
                    idea.description,
                    idea.messages,
                    attachments=attachment_dicts,
                    gemini_files=gemini_files,
                )
                if error_msg:
                    st.error(f"âš ï¸ {error_msg}")
                    st.info("å‰ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’ä¿æŒã—ã¾ã™ã€‚")
                else:
                    idea.draft_spec_markdown = spec_result
                    idea.draft_version += 1

                # Check if this should be the final version based on completeness only
                is_complete, score = check_spec_completeness(
                    manual_md, idea.draft_spec_markdown, idea.draft_version
                )
                print(
                    f"DEBUG: Completeness check - is_complete={is_complete}, "
                    f"score={score}, version={idea.draft_version}"
                )
                if is_complete:
                    idea.is_final = True
                    print(f"DEBUG: Set is_final=True due to completeness score={score}")

                save_ideas(st.session_state.ideas)

            # Generate next questions only if not final
            if not idea.is_final and not error_msg:  # Don't generate questions if error
                with st.spinner("æ¬¡ã®è³ªå•ã‚’æº–å‚™ä¸­â€¦"):
                    try:
                        attachment_dicts, gemini_files = _prepare_attachment_dicts(idea)
                        qs2, q_error = next_questions(
                            manual_md,
                            idea.messages,
                            idea.draft_spec_markdown,
                            num_questions=5,
                            version=idea.draft_version,
                            is_final=idea.is_final,
                            attachments=attachment_dicts,
                        )
                        if q_error:
                            st.warning(f"âš ï¸ è³ªå•ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {q_error}")
                            st.info("ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®è³ªå•ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
                    except Exception as e:
                        print(f"ERROR: Exception in next_questions: {e}")
                        st.warning(f"âš ï¸ è³ªå•ç”Ÿæˆã§äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)[:100]}")
                        st.info("ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®è³ªå•ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
                        # Provide fallback questions
                        qs2 = [
                            "ç¾è¡Œãƒ‰ãƒ©ãƒ•ãƒˆã«æœªè¨˜è¼‰ç®‡æ‰€ãŒã‚ã‚Šã¾ã™ã€‚å›³é¢ã¯å¿…è¦ã§ã™ã‹ï¼Ÿï¼ˆã¯ã„/ã„ã„ãˆï¼‰",
                            "å®Ÿæ–½ä¾‹ã¯è¤‡æ•°ã®ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ãŒã‚ã‚Šã¾ã™ã‹ï¼Ÿï¼ˆã¯ã„/ã„ã„ãˆï¼‰",
                            "ç™ºæ˜ã®åŠ¹æœã«å®šé‡çš„æ ¹æ‹ ã¯ã‚ã‚Šã¾ã™ã‹ï¼Ÿï¼ˆã¯ã„/ã„ã„ãˆï¼‰",
                            "æ—¢å­˜æŠ€è¡“ã¨ã®é•ã„ã‚’æ˜ç¢ºã«èª¬æ˜ã§ãã¾ã™ã‹ï¼Ÿï¼ˆã¯ã„/ã„ã„ãˆï¼‰",
                            "ã“ã®ç™ºæ˜ã®æœ€ã‚‚é‡è¦ãªåˆ©ç‚¹ã¯ä½•ã§ã™ã‹ï¼Ÿï¼ˆã¯ã„/ã„ã„ãˆã§ç­”ãˆã‚‰ã‚Œã‚‹å½¢ã§ç¢ºèªï¼‰",
                        ][:5]
                        q_error = "äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼"

                    print(f"DEBUG: Generated {len(qs2)} questions for version {idea.draft_version}")
                    # Always add questions even if there was an error
                    for q in qs2:
                        append_assistant_message(idea.messages, q)
                        print(f"DEBUG: Added question: {q[:50]}...")
                    save_ideas(st.session_state.ideas)
            else:
                print(
                    f"DEBUG: Skipping question generation - "
                    f"is_final={idea.is_final}, version={idea.draft_version}"
                )
            st.rerun()


def hearing_ui(idea: Idea):
    manual_md = _load_instruction_markdown()

    # File upload section for hearing
    with st.expander("è¿½åŠ ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", expanded=False):
        st.markdown("ãƒ’ã‚¢ãƒªãƒ³ã‚°ä¸­ã«è¿½åŠ ã§å‚è€ƒè³‡æ–™ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã§ãã¾ã™")
        new_files = st.file_uploader(
            "ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠ",
            accept_multiple_files=True,
            help="ãƒ†ã‚­ã‚¹ãƒˆã€PDFã€ç”»åƒã€Wordã€PowerPointãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã§ãã¾ã™ï¼ˆå„10MBä»¥å†…ï¼‰",
            key=f"hearing_upload_{idea.id}",
        )

        if new_files:
            attachments_to_add = []
            for uploaded_file in new_files:
                comment = st.text_input(
                    f"{uploaded_file.name} ã¸ã®ã‚³ãƒ¡ãƒ³ãƒˆ",
                    placeholder="ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã®èª¬æ˜ã‚’å…¥åŠ›...",
                    key=f"hearing_comment_{idea.id}_{uploaded_file.name}",
                )
                attachments_to_add.append((uploaded_file, comment))

            if st.button("ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¿½åŠ ", key=f"add_files_{idea.id}"):
                for uploaded_file, comment in attachments_to_add:
                    try:
                        file_data = process_uploaded_file_with_gemini(uploaded_file, comment)
                        attachment = Attachment(
                            filename=file_data["filename"],
                            content_base64=file_data["content_base64"],
                            comment=file_data["comment"],
                            file_type=file_data["file_type"],
                            upload_time=file_data["upload_time"],
                            gemini_file_id=file_data.get("gemini_file_id"),
                            gemini_mime_type=file_data.get("gemini_mime_type"),
                            extracted_text=file_data.get("extracted_text"),
                        )
                        idea.attachments.append(attachment)
                        st.success(f"{uploaded_file.name} ã‚’è¿½åŠ ã—ã¾ã—ãŸ")
                    except Exception as e:
                        st.error(f"ãƒ•ã‚¡ã‚¤ãƒ« {uploaded_file.name} ã®å‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
                save_ideas(st.session_state.ideas)
                st.rerun()

    # Display existing attachments
    if idea.attachments:
        with st.expander(f"æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ« ({len(idea.attachments)}ä»¶)", expanded=False):
            for att in idea.attachments:
                cols = st.columns([3, 1])
                cols[0].markdown(f"ğŸ“ **{att.filename}** - {att.comment}")
                import base64

                file_bytes = base64.b64decode(att.content_base64)
                cols[1].download_button(
                    "ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                    data=file_bytes,
                    file_name=att.filename,
                    mime=att.file_type,
                    key=f"download_{idea.id}_{att.filename}",
                )

    # Ensure draft exists
    if not idea.draft_spec_markdown:
        with st.spinner("åˆæœŸãƒ‰ãƒ©ãƒ•ãƒˆç”Ÿæˆä¸­â€¦"):
            attachment_dicts, gemini_files = _prepare_attachment_dicts(idea)
            spec_result, error_msg = bootstrap_spec(
                manual_md, idea.description, attachments=attachment_dicts, gemini_files=gemini_files
            )
            if error_msg:
                st.error(f"âš ï¸ {error_msg}")
                st.info("åŸºæœ¬çš„ãªéª¨æ ¼ã‚’ç”Ÿæˆã—ã¾ã—ãŸã€‚")
            idea.draft_spec_markdown = spec_result
            save_ideas(st.session_state.ideas)

    # Auto-generate initial questions if none exist yet (up to 5)
    if not any(m.get("role") == "assistant" for m in idea.messages) and not idea.is_final:
        with st.spinner("åˆå›è³ªå•ã‚’æº–å‚™ä¸­â€¦"):
            attachment_dicts, gemini_files = _prepare_attachment_dicts(idea)
            qs, q_error = next_questions(
                manual_md,
                idea.messages,
                idea.draft_spec_markdown,
                num_questions=5,
                version=idea.draft_version,
                is_final=idea.is_final,
                attachments=attachment_dicts,
            )
            if q_error:
                st.warning(f"âš ï¸ è³ªå•ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {q_error}")
                st.info("ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®è³ªå•ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
            for q in qs:
                append_assistant_message(idea.messages, q)
            save_ideas(st.session_state.ideas)
        st.rerun()

    # Handle final version display
    if idea.is_final:
        version_label = f"ç¬¬{idea.draft_version}ç‰ˆï¼ˆæœ€çµ‚ç‰ˆï¼‰"
        st.subheader(f"ç‰¹è¨±æ˜ç´°æ›¸ - {version_label}")
        st.info("âœ… æ˜ç´°æ›¸ãŒå®Œæˆã—ã¾ã—ãŸã€‚ä»¥ä¸‹ã‹ã‚‰ç·¨é›†ãƒ»ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãŒå¯èƒ½ã§ã™ã€‚")

        # Show full draft expanded for final version
        st.markdown(idea.draft_spec_markdown or "æœªç”Ÿæˆ", unsafe_allow_html=False)

        # Edit and export options
        with st.expander("æ˜ç´°æ›¸ã‚’ç·¨é›†"):
            edited = st.text_area("Markdown", value=idea.draft_spec_markdown, height=500)
            if st.button("ç·¨é›†å†…å®¹ã‚’ä¿å­˜"):
                idea.draft_spec_markdown = edited
                save_ideas(st.session_state.ideas)
                st.success("ä¿å­˜ã—ã¾ã—ãŸã€‚")

        # Export buttons
        st.markdown("### ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ")
        c1, c2 = st.columns(2)
        name_docx, data_docx = export_docx(idea.title, idea.draft_spec_markdown)
        c1.download_button(
            "ğŸ“ Word ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
            data=data_docx,
            file_name=name_docx,
            mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
            use_container_width=True,
            type="primary",
        )
        name_pdf, data_pdf = export_pdf(idea.title, idea.draft_spec_markdown)
        c2.download_button(
            "ğŸ“„ PDF ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
            data=data_pdf,
            file_name=name_pdf,
            mime="application/pdf",
            use_container_width=True,
            type="primary",
        )

        # Show Q&A history at the bottom
        with st.expander("è³ªç–‘å¿œç­”å±¥æ­´", expanded=False):
            # Properly pair questions and answers considering batch format
            questions = []
            answers = []

            j = 0
            while j < len(idea.messages):
                # Collect consecutive assistant messages
                batch_questions = []
                while j < len(idea.messages) and idea.messages[j]["role"] == "assistant":
                    batch_questions.append(_clean_ai_message(idea.messages[j]['content']))
                    j += 1

                # Collect consecutive user messages
                batch_answers = []
                while j < len(idea.messages) and idea.messages[j]["role"] == "user":
                    batch_answers.append(idea.messages[j]['content'])
                    j += 1

                # Pair this batch
                for k in range(len(batch_questions)):
                    if k < len(batch_answers):
                        questions.append(batch_questions[k])
                        answers.append(batch_answers[k])
                    else:
                        questions.append(batch_questions[k])
                        answers.append("(æœªå›ç­”)")

            # Display Q&A pairs (question: answer on same line)
            for q, a in zip(questions, answers):
                st.markdown(f"{q}: {a}")

    # Non-final version display
    elif idea.draft_version == 1:
        # Version 1: Questions first layout
        _render_hearing_section(idea, manual_md, show_questions_first=False)

        # Draft in collapsed expander
        with st.expander("ç”Ÿæˆã•ã‚ŒãŸæ˜ç´°æ›¸ãƒ‰ãƒ©ãƒ•ãƒˆï¼ˆç¬¬1ç‰ˆï¼‰", expanded=False):
            st.markdown(idea.draft_spec_markdown or "æœªç”Ÿæˆ", unsafe_allow_html=False)

    else:
        # Version 2-4: New layout - questions first, then history, then draft
        st.subheader("AI ãƒ’ã‚¢ãƒªãƒ³ã‚°")

        # Show questions first, then Q&A history
        _render_hearing_section(idea, manual_md, show_questions_first=True)

        st.divider()

        # Draft at bottom (collapsed)
        version_label = f"ç¬¬{idea.draft_version}ç‰ˆ"
        with st.expander(f"ç”Ÿæˆã•ã‚ŒãŸæ˜ç´°æ›¸ãƒ‰ãƒ©ãƒ•ãƒˆï¼ˆ{version_label}ï¼‰", expanded=False):
            st.markdown(idea.draft_spec_markdown or "æœªç”Ÿæˆ", unsafe_allow_html=False)

            # Limited export for non-final versions
            st.markdown("---")
            st.caption("â€» ãƒ‰ãƒ©ãƒ•ãƒˆã®ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆï¼ˆç¾åœ¨ã®çŠ¶æ…‹ï¼‰")
            c1, c2 = st.columns(2)
            name_docx, data_docx = export_docx(idea.title, idea.draft_spec_markdown)
            c1.download_button(
                "Word ã‚’ä¿å­˜",
                data=data_docx,
                file_name=name_docx,
                mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
                use_container_width=True,
            )
            name_pdf, data_pdf = export_pdf(idea.title, idea.draft_spec_markdown)
            c2.download_button(
                "PDF ã‚’ä¿å­˜",
                data=data_pdf,
                file_name=name_pdf,
                mime="application/pdf",
                use_container_width=True,
            )


def main():
    load_dotenv()
    st.set_page_config(page_title=APP_TITLE, layout="wide")
    # Basic authentication gate (enabled via env: BASIC_AUTH_USERNAME/PASSWORD)
    render_login_gate(st)
    st.title(APP_TITLE)
    st.caption("ç‰¹è¨±å‡ºé¡˜ã‚¢ã‚¤ãƒ‡ã‚¢ã‚’å¯¾è©±ã§å…·ä½“åŒ–ã—ã€æ˜ç´°æ›¸è‰æ¡ˆã‚’ç”Ÿæˆã—ã¾ã™ã€‚")

    # Dark theme note: instruct Streamlit to use base dark theme via config.toml if desired

    init_session_state()
    # Sidebar user info + logout when auth enabled
    render_sidebar_user(st)
    sidebar_ui()

    ideas: List[Idea] = st.session_state.ideas
    state: AppState = st.session_state.app_state

    # Main area
    if state.show_new_idea_form and state.selected_idea_id:
        # edit selected
        idea = get_idea(ideas, state.selected_idea_id)
        if idea:
            edit_idea_form(idea)
    elif state.show_new_idea_form:
        new_idea_form()
    else:
        # default: list or selected idea view
        if state.selected_idea_id:
            idea = get_idea(ideas, state.selected_idea_id)
            if idea:
                st.header(idea.title)
                st.markdown(f"**ã‚«ãƒ†ã‚´ãƒª:** {idea.category}")
                st.markdown(f"**æ¦‚è¦:** {idea.description}")
                if st.button("å¯¾è©±é–‹å§‹ / ç¶šãã‹ã‚‰"):
                    st.session_state.start_hearing = True
                if st.session_state.get("start_hearing"):
                    hearing_ui(idea)
            else:
                st.info("ã‚¢ã‚¤ãƒ‡ã‚¢ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
        else:
            st.info("å·¦ã®ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰ã‚¢ã‚¤ãƒ‡ã‚¢ã‚’é¸æŠã™ã‚‹ã‹ã€æ–°è¦ä½œæˆã—ã¦ãã ã•ã„ã€‚")


if __name__ == "__main__":
    main()
